First, start by tuning your GAN hyperparameters with gan_impurity_experiments.py. This script uses Optuna to search for cWGAN‑GP settings (latent dimension, number of epochs, critic iterations, gradient‑penalty weight) that minimize the SMAPE on your chosen impurity set. To run it, install the required packages (numpy, pandas, tensorflow, scikit‑learn, and optuna), update the file paths at the top to point to your training and blind‑test CSVs, and simply execute the script. It will print out the best hyperparameters and also demonstrate how to generate synthetic data and evaluate a downstream Random Forest (RF) model on your five blind samples. You can optionally uncomment the provided blocks to explore auxiliary‑loss, selective‑augmentation, or two‑stage strategies as well.

Next, use reproducible_cwgan_rf_xgb_ann.py to compare three machine‑learning algorithms—XGBoost, Random Forest, and an artificial neural network—across three data variants: real‑only, real + synthetic with shared experiment IDs, and real + synthetic with separate IDs. Before running, install any additional dependencies (scikit‑optimize and xgboost), then edit the GAN hyperparameter values at the top of the file to match the best ones from your Optuna search. Also confirm the CSV paths. When you execute this script, it will (re)train the GAN, generate the synthetic datasets, perform Bayesian hyperparameter searches for each ML model, and finally report both cross‑validated SMAPE and blind‑test SMAPE, NRMSE, and R².

Finally, for a per‑compound deep dive, run rf_per_compound_analysis.py. This script rebuilds the three dataset variants again, fits a Bayesian‑tuned Random Forest to each, and then computes SMAPE, NRMSE, and R² on each individual impurity for your five blind samples. As before, update the GAN hyperparameters, synthetic‑data multiplier, and CSV paths at the top, then run the script. It will print a clear table of metrics for every compound and dataset configuration, letting you pinpoint which impurities benefit most—or least—from your synthetic data augmentation.
